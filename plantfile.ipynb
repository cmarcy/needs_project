{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmarcy\\Desktop\\py_projects\\plantfile\\NEEDS_project\n",
      "C:\\Users\\cmarcy\\Desktop\\py_projects\\plantfile\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "from itertools import product\n",
    "\n",
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path)\n",
    "print(path)\n",
    "print(parent)\n",
    "#os.mkdir(path+'\\outputs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in NEMS and NEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all columns match: True\n",
      "\n",
      "rows in active = 18191\n",
      "rows in retire = 829\n",
      "rows in new = 978\n",
      "rows total = 19998\n",
      "\n",
      "rows in needs = 19998\n",
      "rows in needs = total rows: True\n",
      "\n",
      "Index(['Plant_Name', 'UniqueID_Final', 'ORIS_Plant_Code',\n",
      "       'Boiler/Generator/Committed_Unit', 'Unit_ID', 'CAMD_Database_UnitID',\n",
      "       'PlantType', 'Combustion_Turbine/IC_Engine', 'Region_Name',\n",
      "       'State_Name', 'State_Code', 'County', 'County_Code', 'FIPS5',\n",
      "       'Capacity_(MW)', 'Heat_Rate_(Btu/kWh)', 'On_Line_Year',\n",
      "       'Retirement_Year', 'Firing', 'Bottom', 'Cogen?', 'Modeled_Fuels',\n",
      "       'Wet/DryScrubber', 'Scrubber_Online_Year', 'Scrubber_Efficiency'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Reading in nems data (Note: this is only used for QA)\n",
    "nems = pd.read_csv('background/ReEDS_generator_database_final_EIA-NEMS.csv', low_memory=False)\n",
    "#print('number of columns =',nems.shape[1])\n",
    "#print(nems.columns[0:26],nems.columns[26:54],nems.columns[115:])\n",
    "#print()\n",
    "\n",
    "pf = nems[['tech', 'pca', 'ct', 'resource_region', 'cap', 'Nuke60RetireYear',\n",
    "       'Nuke80RetireYear', 'NukeEarlyRetireYear', 'NukeRefRetireYear',\n",
    "       'RetireYear', 'Commercial.Online.Year.Quarter', 'IsExistUnit',\n",
    "       'Fully.Loaded.Tested.Heat.Rate.Btu.kWh...Modeled',\n",
    "       'Plant.NAICS.Description', 'UniqueID', \n",
    "       'Commercial.Online.Year', 'NukeRetireBin', 'EFDcd',\n",
    "       'UniqueID.1', 'RetireYearGiven']].copy()\n",
    "\n",
    "pf['Commercial.Online.Year.Quarter'] = pf['Commercial.Online.Year.Quarter'].str[:4].astype(int)\n",
    "#print('number of columns =',pf.shape[1])\n",
    "#print(pf.head(2))\n",
    "#print()\n",
    "\n",
    "#Reading in needs data\n",
    "needs_active = pd.read_csv('inputs/needs_v6_06-30-2020 - NEEDS v6_active.csv', low_memory=False)\n",
    "needs_retire = pd.read_csv('inputs/needs_v6_06-30-2020 - NEEDS v6_Retired_Through2021.csv', low_memory=False)\n",
    "needs_new = pd.read_csv('inputs/needs_v6_06-30-2020 - NEEDS v6_New_Capacity_Hardwired.csv', low_memory=False)\n",
    "\n",
    "#checking columns\n",
    "na = list(needs_active.columns)\n",
    "nr = list(needs_retire.columns)\n",
    "nn = list(needs_new.columns)\n",
    "check = na==nr==nn\n",
    "print('all columns match:',check)\n",
    "print()\n",
    "\n",
    "#counting rows\n",
    "print('rows in active =',needs_active.shape[0])\n",
    "print('rows in retire =',needs_retire.shape[0])\n",
    "print('rows in new =',needs_new.shape[0])\n",
    "rows_total = needs_active.shape[0]+needs_retire.shape[0]+needs_new.shape[0]\n",
    "print('rows total =',rows_total)\n",
    "print()\n",
    "\n",
    "#appending the needs datasheets into a single dataframe\n",
    "needs = pd.concat([needs_active,needs_retire,needs_new], ignore_index=True)\n",
    "print('rows in needs =',needs.shape[0])\n",
    "print('rows in needs = total rows:',needs.shape[0]==rows_total)\n",
    "print()\n",
    "\n",
    "#getting rid of spaces in the column name\n",
    "needs.columns = needs.columns.str.replace(r'\\s+', '_')\n",
    "\n",
    "#dropping unused columns, comment out for final product\n",
    "needs = needs.drop(columns=['NOx_Comb_Control', 'NOx_Post-Comb_Control', 'SCR_Online_Year','SNCR_Online_Year', 'PM_Control', 'FlueGasConditioning_Flag',\n",
    "                   'Mercury_Controls', 'ACI_Online_Year', 'Mercury_Controls_Efficiency','SO2_Permit_Rate_(lbs/mmBtu)', 'Mode_1_NOx_Rate_(lbs/mmBtu)',\n",
    "                   'Mode_2_NOx_Rate_(lbs/mmBtu)', 'Mode_3_NOx_Rate_(lbs/mmBtu)','Mode_4_NOx_Rate_(lbs/mmBtu)', 'Hg_EMF_for_BIT', 'Hg_EMF_for_SUB',\n",
    "                   'Hg_EMF_for_LIG', 'HCL_Removal', 'DSI_Unit', 'DSI_Online_Year', 'CCS','CCS_Removal', 'C2G', 'C2G_Online_Year', 'BART_Affected_Unit'])\n",
    "\n",
    "print(needs.columns)\n",
    "#needs.to_csv(\"outputs\\\\needs.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching NEEDS data to ReEDS lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with mismatched counties: 0\n",
      "Number of mismatched counties: 0\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [index]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Adding ReEDS Regional Data\n",
    "\n",
    "#this table matches ReEDS regions to counties\n",
    "pca_lookup = pd.read_csv('inputs/pca_lookup.csv')\n",
    "\n",
    "#modifying NEEDS to be able to match with ReEDS\n",
    "needs['County_lower'] = needs['County'].str.lower()\n",
    "needs['County_lower'] = needs['County_lower'].str.replace(' ','')\n",
    "\n",
    "#modifying ReEDS to be able to match with NEEDS\n",
    "pca_lookup = pca_lookup.rename(columns={'State':'State_Name'})\n",
    "pca_lookup['County_lower'] = pca_lookup['County'].str.replace('St. ','St ') \\\n",
    "    .str.replace(' ','').str.lower()\n",
    "pca_lookup = pca_lookup.drop(columns=['County'])\n",
    "#print(pca_lookup.head())\n",
    "\n",
    "#merging needs and the pca lookup table\n",
    "needs_pca = pd.merge(needs,pca_lookup,on=['County_lower','State_Name'],how='left')\n",
    "#this column was only created to facilitate the merge and is no longer needed\n",
    "needs_pca = needs_pca.drop(columns=['County_lower']) \n",
    "#print(needs_pca.head(2))\n",
    "\n",
    "#identify mismatched county data, this DF should be empty\n",
    "pca_na = needs_pca[needs_pca['pca'].isnull()]\n",
    "pca_na_id = pca_na[['County','State_Name']]\n",
    "print('Number of rows with mismatched counties:',pca_na_id.shape[0])\n",
    "pca_na_id = pca_na_id.groupby(['County','State_Name']).first().reset_index()\n",
    "print('Number of mismatched counties:',pca_na_id.shape[0])\n",
    "print()\n",
    "print(pca_na_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding ReEDS Tech Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "20004\n",
      "20565\n",
      "Number of rows with mismatched tech: 0\n"
     ]
    }
   ],
   "source": [
    "#export ReEDS tech names in order to make the lookup table to be imported\n",
    "unique_pt = pd.Series(needs_pca['PlantType'].unique())\n",
    "#print(unique_pt)\n",
    "#unique_pt.to_csv(\"inputs\\\\unique_pt.csv\")\n",
    "\n",
    "tech_lookup = pd.read_csv('inputs/tech_lookup.csv')\n",
    "#print(tech_lookup)\n",
    "#print()\n",
    "\n",
    "tech_lookup.columns = ['PlantType', 'tech'] \n",
    "needs_tech = pd.merge(needs_pca,tech_lookup,on=['PlantType'],how='left')\n",
    "needs_tech['Retire_Yr_OG'] = needs_tech['Retirement_Year']\n",
    "needs_tech['Online_Yr_OG'] = needs_tech['On_Line_Year']\n",
    "#print(needs_tech.head(2))\n",
    "\n",
    "#Tech: creates DUPV\n",
    "#print('rows with PV technology:',needs_tech[needs_tech['tech'] == 'UPV'].shape[0])\n",
    "upv = (needs_tech['tech'] == 'UPV') & (needs_tech['Capacity_(MW)'] >= 5)\n",
    "dupv = (needs_tech['tech'] == 'UPV') & (needs_tech['Capacity_(MW)'] < 5)\n",
    "needs_tech.loc[upv,'tech'] = 'UPV'\n",
    "needs_tech.loc[dupv,'tech'] = 'DUPV'\n",
    "#print('rows with UPV technology:',needs_tech[upv].shape[0])\n",
    "#print('rows with DUPV technology:',needs_tech[dupv].shape[0])\n",
    "\n",
    "#Tech: defines CoalOldScr, CoalOldUns, and coal-new\n",
    "#default coal technology is CoalOldUns, using this code to differentiate between coal labels\n",
    "\n",
    "#creating separate DF of just scrubbed coal units, setting their online year to when the scrubber came online\n",
    "is_scrb = (needs_tech['tech'] == 'CoalOldUns') & (needs_tech['Scrubber_Efficiency'].isnull() == False)\n",
    "scrb = needs_tech[is_scrb].copy()\n",
    "scrb['tech'] = 'CoalOldScr'\n",
    "\n",
    "#coal-new technology is a subset within the scrubbed coal units\n",
    "#print(scrb.head())\n",
    "scrb.loc[(scrb['Wet/DryScrubber'] == 'Wet Scrubber') & (scrb['Scrubber_Online_Year'] >= 1995),'tech'] = 'coal-new' \n",
    "#print(scrb.head())\n",
    "print(scrb.shape[0])\n",
    "\n",
    "#retiring coal plants in main file at year scrubber comes online\n",
    "needs_tech.loc[is_scrb,'Retirement_Year'] = needs_tech['Scrubber_Online_Year']-1\n",
    "needs_tech.loc[is_scrb,'RetireYearGiven'] = True\n",
    "needs_tech.loc[is_scrb,'Wet/DryScrubber'] = np.nan\n",
    "needs_tech.loc[is_scrb,'Scrubber_Online_Year'] = np.nan\n",
    "needs_tech.loc[is_scrb,'Scrubber_Efficiency'] = np.nan\n",
    "#print(needs_tech[is_scrb].head())\n",
    "print(needs_tech.shape[0])\n",
    "\n",
    "#appending the scrb dataframe, creating a new entry for coal plants at year scrubber comes online\n",
    "needs_tech = needs_tech.append(scrb)\n",
    "needs_tech.reset_index(drop=True,inplace=True)\n",
    "print(needs_tech.shape[0])\n",
    "\n",
    "#Note: This code is used to identify mismatched tech data, this DF should be empty\n",
    "tech_na = needs_tech[needs_tech['tech'].isnull()]\n",
    "print('Number of rows with mismatched tech:',tech_na.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding ReEDS Retirement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20565\n",
      "Index(['Boiler/Generator/Committed_Unit', 'Bottom', 'CAMD_Database_UnitID',\n",
      "       'Capacity_(MW)', 'Cogen?', 'Combustion_Turbine/IC_Engine', 'County',\n",
      "       'County_Code', 'FIPS5', 'Firing', 'Heat_Rate_(Btu/kWh)',\n",
      "       'Modeled_Fuels', 'ORIS_Plant_Code', 'On_Line_Year', 'Online_Yr_OG',\n",
      "       'PlantType', 'Plant_Name', 'Region_Name', 'RetireYearGiven',\n",
      "       'Retire_Yr_OG', 'Retirement_Year', 'Scrubber_Efficiency',\n",
      "       'Scrubber_Online_Year', 'State_Code', 'State_Name', 'UniqueID_Final',\n",
      "       'Unit_ID', 'Wet/DryScrubber', 'pca', 'resource_region', 'tech',\n",
      "       'Retire_Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#create columns for RetireYearGiven and Retire_Age_OG\n",
    "needs_retire = needs_tech.copy()\n",
    "needs_retire['Retirement_Year'].fillna(9999, inplace = True)\n",
    "no_retires = needs_retire['Retirement_Year'] == 9999\n",
    "needs_retire.loc[no_retires,'RetireYearGiven'] = False\n",
    "needs_retire.loc[~no_retires,'RetireYearGiven'] = True\n",
    "\n",
    "needs_retire['Retire_Age'] = needs_retire['Retirement_Year'] - needs_retire['On_Line_Year']\n",
    "needs_retire.loc[no_retires,'Retire_Age'] = 9999\n",
    "\n",
    "#non-nuclear retirements\n",
    "\n",
    "lifetimes = pd.read_csv('inputs/lifetimes.csv')\n",
    "lifetimes.set_index('tech',inplace=True)\n",
    "#print(lifetimes)\n",
    "\n",
    "needs_retire.to_csv('outputs\\\\temp.csv')\n",
    "\n",
    "print(len(needs_retire))\n",
    "\n",
    "for i in range(0,len(needs_retire),1):\n",
    "    #print(i)\n",
    "    if needs_retire.loc[i,'Retirement_Year'] == 9999:\n",
    "        tech = needs_retire.loc[i,'tech']\n",
    "        size = needs_retire.loc[i,'Capacity_(MW)']\n",
    "        if size >= 100:\n",
    "            lifetime = lifetimes.loc[tech,'lifetime_big']\n",
    "        elif size < 100:\n",
    "            lifetime = lifetimes.loc[tech,'lifetime_small']\n",
    "        needs_retire.loc[i,'Retirement_Year'] = needs_retire.loc[i,'On_Line_Year'] + lifetime\n",
    "    elif needs_retire.loc[i,'Retirement_Year'] != 9999:\n",
    "        pass\n",
    "\n",
    "print(needs_retire.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nuke plants in NEEDS: 58\n",
      "Number of nuke plants in mapper: 66\n",
      "Number of used nuke plants from mapper: 58\n"
     ]
    }
   ],
   "source": [
    "#nuclear retirements\n",
    "\n",
    "#exported NEEDS nuke names in order to adjust the lookup table that is imported next\n",
    "unique_nuke = needs_retire[needs_retire['tech'] == 'nuclear']\n",
    "unique_nuke2 = pd.Series(unique_nuke['Plant_Name'].unique())\n",
    "print('Number of nuke plants in NEEDS:',len(unique_nuke2))\n",
    "#unique_nuke2.to_csv(\"inputs\\\\unique_nuke.csv\")\n",
    "\n",
    "nuke_mapper = pd.read_csv('inputs/nuke_mapper.csv')\n",
    "#print(nuke_mapper.head())\n",
    "print('Number of nuke plants in mapper:',len(nuke_mapper))\n",
    "\n",
    "needs_nuke = pd.merge(needs_retire,nuke_mapper,on=['Plant_Name','tech'],how='left')\n",
    "nukebin = needs_nuke[needs_nuke['NukeRetireBin'].notnull()]\n",
    "#print(nukebin.head())\n",
    "print('Number of used nuke plants from mapper:',len(nukebin['Plant_Name'].unique()))\n",
    "\n",
    "#NEEDS defaults to 80-yr lifespan for nuclear plants not reporting a retirement year\n",
    "needs_nuke['Nuke80RetireYear'] = needs_nuke['Retirement_Year']\n",
    "\n",
    "#ReEDS defaults to 60-yr lifespan for nuclear plants not reporting a retirement year, adjusted here\n",
    "nuke_80 = (needs_nuke['tech'] == 'nuclear') & (needs_nuke['Retire_Age'] == 80)\n",
    "needs_nuke.loc[nuke_80,'Retirement_Year'] -= 20\n",
    "needs_nuke['Nuke60RetireYear'] = needs_nuke['Retirement_Year']\n",
    "\n",
    "#nuclear plants in needs with 80 year lifespan are actually plants without reported retirement dates\n",
    "#needs_nuke.loc[nuke_80,'RetireYearGiven'] = False\n",
    "\n",
    "#ReEDS NukeRefRetireYear and NukeEarlyRetireYear change retirement assumptions based on nuke bins\n",
    "nukes1 = nuke_80 & (needs_nuke['NukeRetireBin'] == 1)\n",
    "nukes2 = nuke_80 & (needs_nuke['NukeRetireBin'] == 2)\n",
    "#print(nukes1.sum())\n",
    "#print(nukes2.sum())\n",
    "\n",
    "needs_nuke['NukeEarlyRetireYear'] = needs_nuke['Retirement_Year']\n",
    "needs_nuke['NukeRefRetireYear'] = needs_nuke['Retirement_Year']\n",
    "#nuke_check = needs_nuke[nuke_80].copy()\n",
    "#print(nuke_check['NukeEarlyRetireYear'].describe())\n",
    "needs_nuke.loc[nukes1,'NukeEarlyRetireYear'] -= 10\n",
    "needs_nuke.loc[nukes2,'NukeRefRetireYear'] += 20\n",
    "#nuke_check = needs_nuke[nuke_80].copy()\n",
    "#print(nuke_check['NukeEarlyRetireYear'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final formatting \n",
    "needs_final = needs_nuke.copy()\n",
    "needs_final = needs_final.rename(columns={'On_Line_Year':'Commercial.Online.Year.Quarter',\n",
    "                                          'Capacity_(MW)':'cap',\n",
    "                                          'Retirement_Year':'RetireYear'})\n",
    "\n",
    "#creating dummy variables for cooling technologies\n",
    "needs_final['ctt'] = 'dum'\n",
    "needs_final['wst'] = 'dum'\n",
    "needs_final['coolingwatertech'] = 'dum'\n",
    "\n",
    "needs_final.to_csv('outputs\\\\needs_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tech  year  cap_online\n",
      "0  CoalOldScr  1926        10.7\n",
      "1  CoalOldScr  1952        48.0\n",
      "2  CoalOldScr  1953       707.0\n",
      "3  CoalOldScr  1954       847.0\n",
      "4  CoalOldScr  1955       303.0\n",
      "\n",
      "         tech  year  cap_retire\n",
      "932  wind-ons  2047      6929.9\n",
      "933  wind-ons  2048      7023.4\n",
      "934  wind-ons  2049      6337.2\n",
      "935  wind-ons  2050      1392.4\n",
      "936  wind-ons  2054       500.0\n",
      "\n",
      "            tech  year           cap  cap_online  cap_retire  diff\n",
      "4595  CoalOldScr  2115  2.000888e-11         0.0         0.0   0.0\n",
      "4596  CoalOldScr  2116  2.000888e-11         0.0         0.0   0.0\n",
      "4597  CoalOldScr  2117  2.000888e-11         0.0         0.0   0.0\n",
      "4598  CoalOldScr  2118  2.000888e-11         0.0         0.0   0.0\n",
      "4599  CoalOldScr  2119  2.000888e-11         0.0         0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "#high level QA\n",
    "\n",
    "needs_on = needs_final.groupby(['tech','Commercial.Online.Year.Quarter'],as_index=False)['cap'].sum()\n",
    "minyr = int(needs_on['Commercial.Online.Year.Quarter'].min())\n",
    "unique_tech = pd.Series(needs_final['tech'].unique())\n",
    "\n",
    "needs_start = pd.DataFrame(unique_tech, columns=['tech'])\n",
    "needs_start['Commercial.Online.Year.Quarter'] = minyr - 1\n",
    "needs_start['cap'] = 0.0\n",
    "\n",
    "needs_on = pd.merge(needs_on,needs_start,on=['tech','Commercial.Online.Year.Quarter','cap'],how='outer')\n",
    "needs_on = needs_on.rename(columns={'Commercial.Online.Year.Quarter':'year','cap':'cap_online'})\n",
    "print(needs_on.head())\n",
    "print()\n",
    "\n",
    "needs_off = needs_final.groupby(['tech','RetireYear'],as_index=False)['cap'].sum()\n",
    "needs_off['RetireYear'] = needs_off['RetireYear'].astype(int) \n",
    "needs_off = needs_off.rename(columns={'RetireYear':'year','cap':'cap_retire'})\n",
    "maxyr = int(needs_off['year'].max())\n",
    "print(needs_off.tail())\n",
    "print()\n",
    "\n",
    "years = pd.Series(range(minyr-1,maxyr))\n",
    "needs_allyrs = pd.DataFrame(product(unique_tech,years), columns=['tech','year'])\n",
    "needs_allyrs['cap'] = 0.0 \n",
    "\n",
    "needs_allyrs = pd.merge(needs_allyrs,needs_on,on=['tech','year'],how='left')\n",
    "needs_allyrs = pd.merge(needs_allyrs,needs_off,on=['tech','year'],how='left')\n",
    "needs_allyrs = needs_allyrs.fillna(0)\n",
    "needs_allyrs['diff'] = needs_allyrs['cap_online'] - needs_allyrs['cap_retire']\n",
    "\n",
    "for i in range(0,len(needs_allyrs),1):\n",
    "    if needs_allyrs.loc[i,'year'] != minyr-1:\n",
    "        needs_allyrs.loc[i,'cap'] = needs_allyrs.loc[i-1,'cap'] + needs_allyrs.loc[i,'diff']\n",
    "    elif needs_allyrs.loc[i,'year'] == minyr-1:\n",
    "        needs_allyrs.loc[i,'cap'] = 0.0\n",
    "\n",
    "check = needs_allyrs[needs_allyrs['cap'] != 0.0]\n",
    "print(check.tail())\n",
    "\n",
    "#check.to_csv('outputs\\\\needs_check.csv')\n",
    "needs_check = check.copy()\n",
    "needs_check['model'] = 'needs'\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.scatterplot('year', 'cap', data=needs_allyrs, hue='tech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing EIA-NEMS csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEMS COLUMNS SELECTED\n",
      "number of columns = 20\n",
      "Index(['tech', 'pca', 'ct', 'resource_region', 'cap', 'Nuke60RetireYear',\n",
      "       'Nuke80RetireYear', 'NukeEarlyRetireYear', 'NukeRefRetireYear',\n",
      "       'RetireYear', 'Commercial.Online.Year.Quarter', 'IsExistUnit',\n",
      "       'Fully.Loaded.Tested.Heat.Rate.Btu.kWh...Modeled',\n",
      "       'Plant.NAICS.Description', 'UniqueID', 'Commercial.Online.Year',\n",
      "       'NukeRetireBin', 'EFDcd', 'UniqueID.1', 'RetireYearGiven'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print('NEMS ORIGINAL')\n",
    "#print('number of columns =',nems.shape[1])\n",
    "#print(nems.columns[0:26],nems.columns[26:54],nems.columns[115:])\n",
    "#print('note: incomplete list of columns printed here')\n",
    "#print()\n",
    "print('NEMS COLUMNS SELECTED')\n",
    "print('number of columns =',pf.shape[1])\n",
    "print(pf.columns)\n",
    "#print(pf.head(2))\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tech  year  cap_online\n",
      "0  CoalOldScr  1950       250.8\n",
      "1  CoalOldScr  1951        35.0\n",
      "2  CoalOldScr  1952       190.5\n",
      "3  CoalOldScr  1953       361.0\n",
      "4  CoalOldScr  1954      1249.0\n",
      "\n",
      "         tech  year  cap_retire\n",
      "896  wind-ons  2047      6311.9\n",
      "897  wind-ons  2048      7600.2\n",
      "898  wind-ons  2049     11275.6\n",
      "899  wind-ons  2050      4819.1\n",
      "900  wind-ons  2051       180.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#high level QA\n",
    "\n",
    "nems_on = pf.groupby(['tech','Commercial.Online.Year.Quarter'],as_index=False)['cap'].sum()\n",
    "minyr = int(nems_on['Commercial.Online.Year.Quarter'].min())\n",
    "unique_tech = pd.Series(pf['tech'].unique())\n",
    "\n",
    "nems_start = pd.DataFrame(unique_tech, columns=['tech'])\n",
    "nems_start['Commercial.Online.Year.Quarter'] = minyr - 1\n",
    "nems_start['cap'] = 0.0\n",
    "\n",
    "nems_on = pd.merge(nems_on,nems_start,on=['tech','Commercial.Online.Year.Quarter','cap'],how='outer')\n",
    "nems_on = nems_on.rename(columns={'Commercial.Online.Year.Quarter':'year','cap':'cap_online'})\n",
    "print(nems_on.head())\n",
    "print()\n",
    "\n",
    "nems_off = pf.groupby(['tech','RetireYear'],as_index=False)['cap'].sum()\n",
    "nems_off['RetireYear'] = nems_off['RetireYear'].astype(int) \n",
    "nems_off = nems_off.rename(columns={'RetireYear':'year','cap':'cap_retire'})\n",
    "maxyr = int(nems_off['year'].max())\n",
    "print(nems_off.tail())\n",
    "print()\n",
    "\n",
    "years = pd.Series(range(minyr-1,maxyr))\n",
    "nems_allyrs = pd.DataFrame(product(unique_tech,years), columns=['tech','year'])\n",
    "nems_allyrs['cap'] = 0.0 \n",
    "\n",
    "nems_allyrs = pd.merge(nems_allyrs,nems_on,on=['tech','year'],how='left')\n",
    "nems_allyrs = pd.merge(nems_allyrs,nems_off,on=['tech','year'],how='left')\n",
    "nems_allyrs = nems_allyrs.fillna(0)\n",
    "nems_allyrs['diff'] = nems_allyrs['cap_online'] - nems_allyrs['cap_retire']\n",
    "\n",
    "for i in range(0,len(nems_allyrs),1):\n",
    "    if nems_allyrs.loc[i,'year'] != minyr-1:\n",
    "        nems_allyrs.loc[i,'cap'] = nems_allyrs.loc[i-1,'cap'] + nems_allyrs.loc[i,'diff']\n",
    "    elif nems_allyrs.loc[i,'year'] == minyr-1:\n",
    "        nems_allyrs.loc[i,'cap'] = 0.0\n",
    "\n",
    "check = nems_allyrs[nems_allyrs['cap'] != 0.0]\n",
    "#print(check.head(50))\n",
    "\n",
    "#check.to_csv('outputs\\\\nems_check.csv')\n",
    "nems_check = check.copy()\n",
    "nems_check['model'] = 'nems'\n",
    "\n",
    "check_final = nems_check.append(needs_check)\n",
    "check_final.to_csv('outputs\\\\check.csv')\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.scatterplot('year', 'cap', data=nems_allyrs, hue='tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Boiler/Generator/Committed_Unit', 'Bottom', 'CAMD_Database_UnitID',\n",
      "       'cap', 'Cogen?', 'Combustion_Turbine/IC_Engine', 'County',\n",
      "       'County_Code', 'FIPS5', 'Firing', 'Heat_Rate_(Btu/kWh)',\n",
      "       'Modeled_Fuels', 'ORIS_Plant_Code', 'Commercial.Online.Year.Quarter',\n",
      "       'Online_Yr_OG', 'PlantType', 'Plant_Name', 'Region_Name',\n",
      "       'RetireYearGiven', 'Retire_Yr_OG', 'RetireYear', 'Scrubber_Efficiency',\n",
      "       'Scrubber_Online_Year', 'State_Code', 'State_Name', 'UniqueID_Final',\n",
      "       'Unit_ID', 'Wet/DryScrubber', 'pca', 'resource_region', 'tech',\n",
      "       'Retire_Age', 'NukeRetireBin', 'Nuke80RetireYear', 'Nuke60RetireYear',\n",
      "       'NukeEarlyRetireYear', 'NukeRefRetireYear', 'ctt', 'wst',\n",
      "       'coolingwatertech'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(needs_final.columns)\n",
    "needs_review = needs_final[['ORIS_Plant_Code','Unit_ID','pca','tech','cap','Wet/DryScrubber','Scrubber_Efficiency',\n",
    "                            'Online_Yr_OG','Scrubber_Online_Year','RetireYear']].copy()\n",
    "nems_review = nems[['UniqueID','pca','tech','cap','Commercial.Online.Year','RetireYear']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19998\n",
      "23039\n",
      "33174\n"
     ]
    }
   ],
   "source": [
    "needs['needs']=1\n",
    "nems['nems']=1\n",
    "#print(needs.head())\n",
    "needs = needs.rename(columns={'ORIS_Plant_Code':'PID','Unit_ID':'UID'})\n",
    "#needs = needs[['PID','UID','PlantType','Capacity_(MW)','needs']]\n",
    "#print(needs.columns)\n",
    "print(needs.shape[0])\n",
    "\n",
    "nems = nems.rename(columns={'T_PID':'PID',' T_UID':'UID','tech':'tech_nems'})\n",
    "#nems = nems[['PID','UID','tech_nems','cap','nems']]\n",
    "#print(nems.columns)\n",
    "print(nems.shape[0])\n",
    "\n",
    "combo = pd.merge(needs,nems,on=['PID','UID'],how='outer')\n",
    "print(combo.shape[0])\n",
    "#combo.to_csv('outputs\\\\combo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
